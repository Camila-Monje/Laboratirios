#ej 1
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

X = np.array([1, 2, 3, 4, 5, 6], dtype=float) # Entrada
Y = 3 * X + 2  # Salida

# Creamos el modelo
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[1])
])

# Compilamos el modelo
model.compile(optimizer='sgd', loss='mean_squared_error')

# Entrenamos el modelo
model.fit(X, Y, epochs=500)

# Hacemos predicciones
print("Predicción para X = 5:", model.predict(np.array([5.0])))
print("Predicción para X = 3.3:", model.predict(np.array([3.3])))


# ej1 prueba
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Datos de entrenamiento
X = np.array([1, 2, 3, 4, 5, 6], dtype=float)
Y = 3 * X + 2

# Crear y entrenar el modelo
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[1])
])
model.compile(optimizer='sgd', loss='mean_squared_error')
model.fit(X, Y, epochs=500, verbose=0)  # Entrenamos sin imprimir todas las épocas

# Pedir dato al usuario
entrada = float(input("Ingresa un valor de X: "))
resultado = model.predict(np.array([entrada]))
print(f"Para X = {entrada}, la red predice Y = {resultado[0][0]}")

# Mostrar gráfico para comprobar el ajuste
predicciones = model.predict(X)
plt.scatter(X, Y, label='Datos reales')
plt.plot(X, predicciones, color='red', label='Predicción del modelo')
plt.scatter(entrada, resultado[0][0], color='green', label='Dato ingresado')
plt.legend()
plt.title("Red Neuronal Simple: Y = 3X + 2")
plt.xlabel("X")
plt.ylabel("Y")
plt.grid(True)
plt.show()



#ej 2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Datos de entrenamiento
X = np.array([1, 2, 3, 4, 5, 6], dtype=float)
Y = 3 * X + 2

# Modelo correcto para regresión
model = keras.Sequential([
    layers.Dense(25, activation='relu', input_shape=[1]),
    layers.Dense(25, activation='relu'),
    layers.Dense(1)  # SIN activación, porque queremos regresión
])

# Compilar con pérdida de regresión
model.compile(optimizer='adam', loss='mean_squared_error')

# Entrenar
model.fit(X, Y, epochs=1500, batch_size=32, validation_split=0.2, verbose=0)

# Probar con entrada del usuario
entrada = float(input("Ingresa un valor de X: "))
resultado = model.predict(np.array([entrada]))
print(f"Para X = {entrada}, la red predice Y = {resultado[0][0]}")



#ej 3
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# 1. Cargar el archivo CSV
df = pd.read_csv("spam text data.csv")

# 2. Renombrar columnas
df.rename(columns={"Category": "label", "Message": "text"}, inplace=True)

# 3. Limpiar el texto
df['text_clean'] = df['text'].str.lower().str.replace(r'[^a-z\s]', '', regex=True)

# 4. Convertir etiquetas a números
df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})

# 5. Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['label_num'], test_size=0.2, random_state=42)

# 6. Vectorizar texto con TF-IDF
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 7. Entrenar modelo de regresión logística
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# 8. Predecir y evaluar
y_pred = model.predict(X_test_tfidf)

print("=== REPORTE DE CLASIFICACIÓN ===")
print(classification_report(y_test, y_pred, target_names=["ham", "spam"]))

# 9. Mostrar matriz de confusión
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["ham", "spam"])
disp.plot(cmap="Blues")
plt.title("Matriz de Confusión")
plt.show()

# 10. Probar el modelo con un mensaje personalizado
mensaje = ["¡Gana dinero fácil ahora mismo! Haz clic aquí."]
mensaje_tfidf = vectorizer.transform(mensaje)
prediccion = model.predict(mensaje_tfidf)

print("\nMensaje de prueba:", mensaje[0])
print("Predicción:", "SPAM" if prediccion[0] == 1 else "HAM (no spam)")


# ej4
import pandas as pd

data = {
    "Student Name": ["Mila", "Lau", "Dylan", "Samu"],
    "Student Age": [20, 21, 22, 23],
    "No. of Lab completed.": [10, 8, 9, 7],
    "Average score": [88.5, 76.0, 92.3, 85.0]
}

# Crear DataFrame
df = pd.DataFrame(data)

# Guardar como Excel
df.to_excel("student_data.xlsx", index=False)


#ej4
import pandas as pd

# Leer el archivo
df = pd.read_excel("student_data.xlsx")

# Convertir DataFrame a lista de diccionarios (una fila por dict)
records = df.to_dict(orient="records")

# Usar map + lambda para imprimir cada registro
list(map(lambda x: print(
    f"Name: {x['Student Name']}, Age: {x['Student Age']}, Labs: {x['No. of Lab completed.']}, Avg Score: {x['Average score']}"
), records))


# ej5
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# === Datos del ejercicio ===
data = {
    "Average purchase cost": [750, 1245, 230, 533, 490, 1000, 190, 900, 600, 50, 1100, 930, 450, 330, 750],
    "Avg # of purchases with credit card": [3, 1, 4, 3, 2, 1, 0, 3, 2, 1, 0, 4, 3, 2, 0]
}
df = pd.DataFrame(data)

# === Escalar datos ===
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

# === Método del Codo ===
inertia = []
K_range = range(1, 10)
for k in K_range:
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(scaled_data)
    inertia.append(model.inertia_)

# Graficar método del codo
plt.figure()
plt.plot(K_range, inertia, marker='o')
plt.title("Método del Codo")
plt.xlabel("Número de Clusters (k)")
plt.ylabel("Inercia (Distancia Total a Centroides)")
plt.grid(True)
plt.show()

# === KMeans con 3 clusters (ejemplo recomendado) ===
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(scaled_data)

# === Visualizar Clusters ===
plt.figure()
sns.scatterplot(
    x="Average purchase cost",
    y="Avg # of purchases with credit card",
    hue="Cluster",
    palette="viridis",
    data=df
)
plt.title("Segmentación de Clientes (KMeans, StandardScaler)")
plt.show()

# === Ver resultados finales ===
print(df.sort_values("Cluster"))



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# === Paso 1: Cargar el dataset ===
df = pd.read_csv("Clustering.csv")

# === Paso 2: Seleccionar columnas x y y ===
data = df[['x', 'y']]

# === Paso 3: Eliminar NaN (valores faltantes) ===
data = data.dropna()

# === Paso 4: Elbow Method ===
inertia = []
K_range = range(1, 10)
for k in K_range:
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(data)
    inertia.append(model.inertia_)

# Graficar el codo
plt.figure()
plt.plot(K_range, inertia, marker='o', color='orange')
plt.title("Elbow Method for Optimal K")
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Inertia")
plt.grid(True)
plt.show()

# === Paso 5: Aplicar KMeans con K=3 (óptimo) y K=5 (arbitrario) ===
kmeans_opt = KMeans(n_clusters=3, random_state=42)
data['Cluster_3'] = kmeans_opt.fit_predict(data)

kmeans_arb = KMeans(n_clusters=5, random_state=42)
data['Cluster_5'] = kmeans_arb.fit_predict(data[['x', 'y']])

# === Paso 6: Visualizar resultados ===
fig, ax = plt.subplots(1, 2, figsize=(12, 5))

sns.scatterplot(data=data, x='x', y='y', hue='Cluster_3', palette='Set1', ax=ax[0])
ax[0].set_title("KMeans Clustering (K=3)")

sns.scatterplot(data=data, x='x', y='y', hue='Cluster_5', palette='Set2', ax=ax[1])
ax[1].set_title("KMeans Clustering (K=5)")

plt.tight_layout()
plt.show()
